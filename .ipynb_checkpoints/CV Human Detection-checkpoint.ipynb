{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING ALL THE LIBRARIES NEEDED\n",
    "\n",
    "import glob                # For getting all filenames of the imagess in the given folder\n",
    "from PIL import Image      # For opening the image\n",
    "import numpy as np         # For array manipulations\n",
    "%matplotlib inline         \n",
    "from matplotlib import pyplot as plt  # For dislpaying images\n",
    "import imageio as io                   # For writing the images to the device\n",
    "import math as m                       # For math functions, square root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For displaying the image using matplotlib\n",
    "\n",
    "def display(img):                  \n",
    "    plt.imshow(img,cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load all the images to training vectors.\n",
    "\n",
    "train = 0                      # To mark the end of positive training samples                               \n",
    "test = 0                       # To mark the end of positive testing samples\n",
    "trainx = []                    # List to store all training images\n",
    "trainy = []                    # List to store all training output\n",
    "def load_train(path1, path2):                            # Function to load images\n",
    "    trn = 0\n",
    "    for filename in glob.glob(path1+'\\\\*.bmp'):          # Getting all the filenames of positive images\n",
    "        img = np.array(Image.open(filename))             # Opening the image and converrting to numpy array\n",
    "        trainx.append(img)                               # Appending to the train image array\n",
    "        trainy.append(1)                                 # Appending to the test array, the value 1 for positive\n",
    "        trn += 1\n",
    "    train = trn\n",
    "    for filename in glob.glob(path2+'\\\\*.bmp'):          # Getting all file names of negative images\n",
    "        img = np.array(Image.open(filename))             # Opening the image and converting to numpy array\n",
    "        trainx.append(img)                               # Appending to train image array\n",
    "        trainy.append(0) # Appending to the test array, the value 0 for negative\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load all the images to training vectors.\n",
    "\n",
    "testx = []                                       # List to store all testing images \n",
    "testy = []                                       # List to store all training output\n",
    "def load_test(path1, path2):                      # Function to load images\n",
    "    tst = 0\n",
    "    for filename in glob.glob(path1+'\\\\*.bmp'):   # Getting all the filenames of positive images\n",
    "        img = np.array(Image.open(filename))      # Opening the image and converrting to numpy array\n",
    "        testx.append(img)                         # Appending to the train image array\n",
    "        testy.append(1)                           # Appending to the test array, the value 1 for positive\n",
    "        tst += 1\n",
    "    test = tst\n",
    "    for filename in glob.glob(path2+'\\\\*.bmp'):  # Getting all file names of negative images\n",
    "        img = np.array(Image.open(filename))     # Opening the image and converting to numpy array\n",
    "        testx.append(img)                        # Appending to train image array\n",
    "        testy.append(0)                           # Appending to the test array, the value 0 for negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert the image to grayscale image\n",
    "\n",
    "def convert_gray(img):\n",
    "    conversion = np.array([0.229,0.587,0.114])                          # List to multiply to get grayscale image\n",
    "    gray_img_array = np.around(np.dot(img,conversion))                  # Taking dot product and then rounding off to get grayscale image\n",
    "    return gray_img_array                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION FOR CALCULATING GRADIENT\n",
    "\n",
    "def gradient(img,fd,sd):\n",
    "    # DEFINING PREWITT OPERATORS FOR GRADIENT CALCULATION\n",
    "\n",
    "    prewitt_x = np.array([[-1,0,1],[-1,0,1],[-1,0,1]])       # Prewitt x operator defined\n",
    "    prewitt_y = np.array([[1,1,1],[0,0,0],[-1,-1,-1]])       # Prewitt y operator defined\n",
    "    prfd, prsd = prewitt_x.shape                             # Storing the dimensions of prewitt masks into variables\n",
    "    gx = np.zeros((fd,sd),dtype = np.float)                    # Defining gradient x array \n",
    "    gy = np.zeros((fd,sd),dtype = np.float)                    # Defining gradient y array \n",
    "    gxn = np.zeros((fd,sd),dtype = np.float)                   # Defining the normalized gradient x array\n",
    "    gyn = np.zeros((fd,sd),dtype = np.float)                   # Defining the normalized gradient y array\n",
    "    gm = np.zeros((fd,sd),dtype = np.float)                    # Defining the gradient magnitude array\n",
    "    temp_gradient = np.zeros((prfd,prsd),dtype = np.float)     # Defining temporary array that will store the slice of smoothed image array for direct matrix multiplication\n",
    "    for i in range(fd-prfd+1):\n",
    "        for j in range(sd-prfd+1):\n",
    "            temp_gradient = img[(i):(3+i),(j):(3+j)]       # Storing the slice of smoothed image array in temporary array\n",
    "            gx[1+i,1+j] = np.sum(np.multiply(temp_gradient, prewitt_x))  # Applying convolution for gradient x by directly multpilying the slice of matrix with prewitt x operator\n",
    "            gy[1+i,1+j] = np.sum(np.multiply(temp_gradient, prewitt_y))  # Applying convolution for gradient y by directly multiplying the slice of matrix with prewitt y operator\n",
    "    gxn = np.absolute(gx)/3                 # Forming normalized gradient x matrix from gradient x matrix by taking absolute value using np.absolute() and dividing by three\n",
    "    gyn = np.absolute(gy)/3                 # Forming normalized gradient y matrix from gradient y matrix by taking absolute value using np.absolute() and dividing by three\n",
    "    gm = np.hypot(gxn,gyn)/np.sqrt(2)       # Forming the normalized gradient magnitude array by using np.hypot() which takes under root of sum of squares of normalized gradient x and normalized gradient y and then dividing by square root of 2 for normalization\n",
    "    return np.around(gx),np.around(gy),np.around(gxn),np.around(gyn),np.around(gm)       # Returning gradient x, gradient y, normalized gradient x, normalized gradient y and normalized gradient magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute gradient angle, and then wrapping it around -10 to 170\n",
    "\n",
    "def angle(gy,gx):\n",
    "    ga = np.degrees(np.arctan2(gy,gx))                # To compute the gradient angle and then converting it into degrees\n",
    "    for i in range(ga.shape[0]):                     \n",
    "        for j in range(ga.shape[1]):\n",
    "            if ga[i,j]<-10:                           # Mapping negative angles\n",
    "                ga[i,j]+=180\n",
    "            elif ga[i,j]>=170:                        # Mapping angles greater than 170\n",
    "                ga[i,j]-=180\n",
    "    return ga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to proportionately divide gradient magnitude into histogram bins\n",
    "\n",
    "def divide(mag, ang, x):\n",
    "    c = abs(x-ang)/20                       # Dividing the magnitude and then returning\n",
    "    return c*mag,(1-c)*mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the histogram of each 8x8 pixel cell, calling divide to split the gradient magnitude proportionally and\n",
    "# then adding it to bins\n",
    "def cell_histo(ga,gm):\n",
    "    histogram = [0]*9\n",
    "    for i in range(ga.shape[0]):\n",
    "        for j in range(ga.shape[1]):\n",
    "            if ga[i,j]<=0:\n",
    "                mag1,mag2=divide(gm[i,j],ga[i,j],0)\n",
    "                histogram[8]+=mag1\n",
    "                histogram[0]+=mag2\n",
    "            elif ga[i,j]>=0 and ga[i,j]<=20:\n",
    "                mag1,mag2=divide(gm[i,j],ga[i,j],20)\n",
    "                histogram[0]+=mag1\n",
    "                histogram[1]+=mag2\n",
    "            elif ga[i,j]>=20 and ga[i,j]<=40:\n",
    "                mag1,mag2=divide(gm[i,j],ga[i,j],40)\n",
    "                histogram[1]+=mag1\n",
    "                histogram[2]+=mag2\n",
    "            elif ga[i,j]>=40 and ga[i,j]<=60:\n",
    "                mag1,mag2=divide(gm[i,j],ga[i,j],60)\n",
    "                histogram[2]+=mag1\n",
    "                histogram[3]+=mag2\n",
    "            elif ga[i,j]>=60 and ga[i,j]<=80:\n",
    "                mag1,mag2=divide(gm[i,j],ga[i,j],80)\n",
    "                histogram[3]+=mag1\n",
    "                histogram[4]+=mag2\n",
    "            elif ga[i,j]>=80 and ga[i,j]<=100:\n",
    "                mag1,mag2=divide(gm[i,j],ga[i,j],100)\n",
    "                histogram[4]+=mag1\n",
    "                histogram[5]+=mag2\n",
    "            elif ga[i,j]>=100 and ga[i,j]<=120:\n",
    "                mag1,mag2=divide(gm[i,j],ga[i,j],120)\n",
    "                histogram[5]+=mag1\n",
    "                histogram[6]+=mag2\n",
    "            elif ga[i,j]>=120 and ga[i,j]<=140:\n",
    "                mag1,mag2=divide(gm[i,j],ga[i,j],140)\n",
    "                histogram[6]+=mag1\n",
    "                histogram[7]+=mag2\n",
    "            elif ga[i,j]>=140 and ga[i,j]<=160:\n",
    "                mag1,mag2=divide(gm[i,j],ga[i,j],160)\n",
    "                histogram[7]+=mag1\n",
    "                histogram[8]+=mag2\n",
    "            elif ga[i,j]>=160:\n",
    "                mag1,mag2=divide(gm[i,j],ga[i,j],160)\n",
    "                histogram[0]+=mag1\n",
    "                histogram[8]+=mag2\n",
    "    return histogram\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the L2 Norm of each histogram, taking 2x2 cells and returning 36xq vector\n",
    "\n",
    "\n",
    "def normalize(histo):\n",
    "    sqsum = 0                                                     # To store square sum\n",
    "    norm_histo = []                                               # To store 36x1 histogram\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            for k in range(9):\n",
    "                sqsum += (histo[i,j,k]*histo[i,j,k])                # Taking square sum of each value\n",
    "                norm_histo.append(histo[i,j,k])\n",
    "    lval = m.sqrt(sqsum)                                           # Taking sqaure root of square sum\n",
    "    norm_histo = np.array(norm_histo)                              # Converting list to numpy array for easier calculations\n",
    "    if lval!=0:                                                    # If not zero only then divide else let it be, it will remain 0\n",
    "        norm_histo = norm_histo/lval\n",
    "    return norm_histo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate descriptor of all images, it calls cell_histo to calculate histograms of all 8x8 cells, normalize to do L2\n",
    "# normalization\n",
    "\n",
    "\n",
    "def hog_descriptor(ga,gm):\n",
    "    x = int(ga.shape[0]/8)\n",
    "    y = int(ga.shape[1]/8)\n",
    "    histogram = np.zeros((x,y,9))\n",
    "    index = [0,0]\n",
    "    for i in range(x):\n",
    "        for j in range(y):\n",
    "            temp = cell_histo(ga[index[0]:(index[0]+8),index[1]:(index[1]+8)],gm[index[0]:(index[0]+8),index[1]:(index[1]+8)])\n",
    "            histogram[i,j]=temp\n",
    "            index[1] += 8\n",
    "        index[0] += 8\n",
    "        index[1] = 0\n",
    "    norm_histo = []\n",
    "    for i in range(x-1):\n",
    "        for j in range(y-1):\n",
    "            temp = normalize(histogram[i:(i+2),j:(j+2)])\n",
    "            temp = temp.tolist()\n",
    "            norm_histo.extend(temp)\n",
    "    norm_histo = np.array(norm_histo)\n",
    "    return norm_histo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate RELU\n",
    "\n",
    "\n",
    "def relu(x):\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            if x[i,j]<0:\n",
    "                x[i,j]=0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate sigmoid\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to implament neural network, to train it.\n",
    "\n",
    "def neural_net(inp,out,hidden):\n",
    "    aplha = 0.01                                               # Initializing the learning rate\n",
    "    col = inp.shape[1]                                         \n",
    "    col2 = 1\n",
    "    w1 = np.random.randn(col,hidden)                          # Weight for layer 1\n",
    "    w1 = np.multiply(w1,m.sqrt(2/int(col+hidden)))            # Faactoring the weight\n",
    "    w2 = np.random.randn(hidden,col2)                         # Weight for layer 2\n",
    "    w2 = np.multiply(w2,m.sqrt(2/int(hidden+col2)))           # Factoring the weight\n",
    "    w1bias = np.random.randn(hidden)                          # Bias for layer 1\n",
    "    w1bias = np.multiply(w1bias,m.sqrt(2/int(hidden)))\n",
    "    w2bias = np.random.randn(col2)                           # Bias for layer 2\n",
    "    w2bias = np.multiply(w2bias,m.sqrt(2/int(col2)))\n",
    "    err_curve=np.zeros((100,1))                              # Error array for each epoch\n",
    "    epoch = 0\n",
    "    while epoch<100:                                         # Doing forward and backward propogation for each epoch\n",
    "        for i in range(inp.shape[0]):\n",
    "            x = inp[i,:].reshape([1,-1])\n",
    "            z = relu((x.dot(w1)+w1bias))                     # Computing values for hidden layer\n",
    "            y = sigmoid((z.dot(w2)+w2bias))                  # Computing values for output layer\n",
    "            err = out[i]-y                                   # Error for output layer             \n",
    "            sqerr = 0.5*err*err                              # Square error                      \n",
    "            del_out=(-1*err)*(1-y)*y                         \n",
    "            del_layer2=z.T.dot(del_out)\n",
    "            del_layer20=np.sum(del_out,axis=0)\n",
    "            zz=np.zeros_like(z)\n",
    "            for k in range(hidden):\n",
    "            \n",
    "                if(z[0][k]>0):\n",
    "                    zz[0][k]=1\n",
    "                else:\n",
    "                    zz[0][k]=0\\\n",
    "                       \n",
    "            del_hidden= del_out.dot(w2.T)*zz\n",
    "            del_layer1=x.T.dot(del_hidden)\n",
    "            delta_layer10=np.sum(del_hidden,axis=0)\n",
    "            \n",
    "            w2-= aplha*del_layer2\n",
    "            w2bias-= aplha*del_layer20\n",
    "            w1-= aplha*del_layer1\n",
    "            w1bias-= aplha*delta_layer10\n",
    "            err_curve[epoch] = sqerr/inp.shape[0]\n",
    "        print('Epoch %d: err %f'%(epoch,np.mean(sqerr)/inp.shape[0]))\n",
    "        epoch +=1\n",
    "    return w1,w1bias,w2,w2bias,err_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict values for my neural network\n",
    "\n",
    "def predict(w,wb,v,vb,Output_descriptor):\n",
    "    Number_of_test_image,number_of_attribute=Output_descriptor.shape\n",
    "    predict=[]\n",
    "    for k in range(Number_of_test_image):\n",
    "            x=Output_descriptor[k,:].reshape([1,-1])\n",
    "            z=relu((x.dot(w)+wb))\n",
    "            y=sigmoid(z.dot(v)+vb)\n",
    "            predict.append(y)\n",
    "    return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function that calls every other function\n",
    "\n",
    "def main():\n",
    "    load_train('C:\\\\Users\\\\arjan\\\\Untitled Folder 2\\\\Train_Positive','C:\\\\Users\\\\arjan\\\\Untitled Folder 2\\\\Train_Negative') # Loading all training images\n",
    "    load_test('C:\\\\Users\\\\arjan\\\\Untitled Folder 2\\\\Test_Positive','C:\\\\Users\\\\arjan\\\\Untitled Folder 2\\\\Test_Neg')   # Loading all test images\n",
    "\n",
    "    for i in range(len(trainx)):\n",
    "        trainx[i] = convert_gray(trainx[i])         # Converting train images to grayscale\n",
    "    for i in range(len(testx)):\n",
    "        testx[i] = convert_gray(testx[i])           # Converting test images to grayscale\n",
    "\n",
    "    fvector = np.zeros((20,7524))                   # Creating HOG descriptor for training images\n",
    "    fvector2 = np.zeros((10,7524))                  # Creating HOG descriptor for test images\n",
    "\n",
    "    for i in range(len(trainx)):\n",
    "        gx,gy,gxn,gyn,gm = gradient(trainx[i],trainx[i].shape[0],trainx[i].shape[1])    # Calculating gradient magnitude of all training images\n",
    "        ga = angle(gy,gx)                          # Calculating gradient angle of all training images\n",
    "        fvector[i] = hog_descriptor(ga,gm)         # Storing HOG descriptor for all images\n",
    "\n",
    "\n",
    "    for i in range(len(testx)):\n",
    "        gx,gy,gxn,gyn,gm = gradient(testx[i],testx[i].shape[0],testx[i].shape[1])  # Calculating gradient magnitude of all testing images\n",
    "        ga = angle(gy,gx)                        # Calculating gradient angle of all training images\n",
    "#         io.imwrite('D:\\\\CV\\\\Project 2\\\\Project 2 report\\\\Test Gradient Images\\\\GradientTest{}.bmp'.format(i),gm) # Writing the images to directory\n",
    "        fvector2[i] = hog_descriptor(ga,gm)       # Storing HOG descriptor for all images\n",
    "    \n",
    "\n",
    "    hidden = [250,500,1000]    # List with values of Hidden neurons\n",
    "\n",
    "\n",
    "    for i in range(len(hidden)):   # running neural networks for different values of hidden neurons\n",
    "        print('HIDDEN LAYER = %d'%(hidden[i]))\n",
    "        print('\\n\\n')\n",
    "        w1,w1bias,w2,w2bias,err_curve = neural_net(fvector,np.array(trainy),hidden[i])\n",
    "        predicted_output=predict(w1,w1bias,w2,w2bias,fvector2)\n",
    "        pre=[]\n",
    "\n",
    "        for check in predicted_output:\n",
    "            if(check >=0.5):\n",
    "                pre.append(1)\n",
    "            else:\n",
    "                pre.append(0)\n",
    "            print(check)\n",
    "\n",
    "        print(len(pre))\n",
    "\n",
    "        correct=0\n",
    "        wrong=0\n",
    "\n",
    "        for i in range(len(pre)):\n",
    "            if(pre[i]==testy[i]):\n",
    "                correct+=1\n",
    "            else:\n",
    "                wrong+=1\n",
    "\n",
    "        print('correct = %d'%(correct))\n",
    "        print('wrong = %d'%(wrong))\n",
    "\n",
    "        print(pre)\n",
    "        print(testy)\n",
    "        print('\\n\\n\\n')\n",
    "    \n",
    "    \n",
    "    \n",
    "# #     f = open('D:\\\\CV\\\\Project 2\\\\Project 2 report\\\\HOG_crop001278a.txt','w+')\n",
    "# #     f2 = open('D:\\\\CV\\\\Project 2\\\\Project 2 report\\\\HOG_crop001045b.txt','w+')\n",
    "# #     print('The HOG descriptor for the image crop001278a.bmp\\n\\n')\n",
    "#     for i in range(len(fvector[5])):\n",
    "#         f.write('%.17f\\n'%(fvector[5,i]))\n",
    "#     print('\\n\\nThe HOG descriptor for the image crop001045b.bmp\\n\\n')\n",
    "#     for i in range(len(fvector2[3])):\n",
    "#         f2.write('%.17f\\n'%(fvector2[3,i]))\n",
    "#     f.close()\n",
    "#     f2.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "The directory 'D:\\\\CV\\\\Project 2\\\\Project 2 report\\\\Test Gradient Images' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-39fe8a7f23d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-35-c801ef1308bf>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mgx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgxn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgyn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtestx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtestx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Calculating gradient magnitude of all testing images\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mga\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mangle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgx\u001b[0m\u001b[1;33m)\u001b[0m                        \u001b[1;31m# Calculating gradient angle of all training images\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'D:\\\\CV\\\\Project 2\\\\Project 2 report\\\\Test Gradient Images\\\\GradientTest{}.bmp'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgm\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Writing the images to directory\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mfvector2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhog_descriptor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mga\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgm\u001b[0m\u001b[1;33m)\u001b[0m       \u001b[1;31m# Storing HOG descriptor for all images\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\imageio\\core\\functions.py\u001b[0m in \u001b[0;36mimwrite\u001b[1;34m(uri, im, format, **kwargs)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;31m# Get writer and write first\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m     \u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_writer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"i\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mwriter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\imageio\\core\\functions.py\u001b[0m in \u001b[0;36mget_writer\u001b[1;34m(uri, format, mode, **kwargs)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[1;31m# Create request object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m     \u001b[0mrequest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[1;31m# Get format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\imageio\\core\\request.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, uri, mode, **kwargs)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[1;31m# Parse what was given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_uri\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         \u001b[1;31m# Set extension\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\imageio\\core\\request.py\u001b[0m in \u001b[0;36m_parse_uri\u001b[1;34m(self, uri)\u001b[0m\n\u001b[0;32m    276\u001b[0m                 \u001b[0mdn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 278\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The directory %r does not exist\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: The directory 'D:\\\\CV\\\\Project 2\\\\Project 2 report\\\\Test Gradient Images' does not exist"
     ]
    }
   ],
   "source": [
    "# Function for calling main function\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
